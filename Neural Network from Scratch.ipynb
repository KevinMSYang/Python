{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network from Scratch in Python\n",
    "Kevin Yang\n",
    "50541650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv('sample_dewpoint_dataset.csv')\n",
    "# check all rows and column for null value\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Tanh\n",
    "def tanh(x):\n",
    "    return np.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = set(dataset.columns.values)\n",
    "cols -= set(['temperature', 'humidity', 'wind_speed'])\n",
    "col = set(dataset.columns.values)\n",
    "col -= set(['dew_point'])\n",
    "Y = dataset[list(cols)]\n",
    "X = dataset[list(col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights randomly with mean 0 (range (-1,1))\n",
    "w0 = 2*np.random.random((3,1)) -1\n",
    "print(w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propagation\n",
    "l0 = X\n",
    "l1 = np.dot(l0, w0)\n",
    "print(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tanh(l1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the error:\n",
    "output_error = Y - output\n",
    "print(output_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backpropagation\n",
    "def tanh_deriv(x):\n",
    "    return 1.0 - np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the output error in terms of the hidden layer output\n",
    "output_delta = output_error * tanh_deriv(output)\n",
    "print(output_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_per_weight = np.dot(l0.T, output_delta)\n",
    "print(err_per_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 += err_per_weight\n",
    "print(\"Weights nows: \\n\", w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boundle up forward propagation steps:\n",
    "def forward(X, w0):\n",
    "    l0 = X\n",
    "    l1 = np.dot(l0, w0)\n",
    "    output = tanh(l1)\n",
    "    return output\n",
    "output = forward(X, w0)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bundle up the backpropagation steps:\n",
    "def backprop(l0, w0, output, Y):\n",
    "    output_error = Y - output\n",
    "    output_delta = output_error * tanh_deriv(output)\n",
    "    err_per_weight = np.dot(l0.T, output_delta)\n",
    "    w0 += err_per_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to compute the Mean Square Error (MSE)\n",
    "def MSE(truth, estimate):\n",
    "    return np.mean(np.square(truth - estimate))\n",
    "\n",
    "print(\"MSE after scond trining step: %.3f\" % MSE(Y, forward(X, w0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, w0):\n",
    "    output = forward(X, w0)\n",
    "    backprop(X, w0, output, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = 2*np.random.random((3,1)) -1\n",
    "for i in range(100):\n",
    "    mse_before = MSE(Y, forward(X, w0))\n",
    "    train(X, Y, w0)\n",
    "    mse_after = MSE(Y, forward(X, w0))\n",
    "    if i %10 == 0 or i == 99:\n",
    "        print(\"i: %3i MSE before: %0.5f after: %0.5f\" % (i, mse_before, mse_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-layer Network\n",
    "# initial weights for this network.\n",
    "w0 = 2 * np.random.random((3,5))-1\n",
    "w1 = 2 * np.random.random((5,1))-1\n",
    "w2 = 2 * np.random.random((1,1))-1\n",
    "NN3 = [w0, w1, w2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _forward(NN, X):\n",
    "    l0 = X\n",
    "    l1 = tanh(np.dot(l0, NN[0]))\n",
    "    l2 = tanh(np.dot(l1, NN[1]))\n",
    "    l3 = tanh(np.dot(l2, NN[2]))\n",
    "    output = l3\n",
    "    return (output, l2, l1, l0)\n",
    "   # output = l2\n",
    "    #return (output, l1, l0)\n",
    "def forward(NN, X):\n",
    "    return _forward(NN, X)[1]\n",
    "    #return _forward(NN, X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(NN, X, Y):\n",
    "    output, l2, l1, l0 = _forward(NN, X)\n",
    "    output_err = Y - output\n",
    "    w2_delta = output_err * tanh_deriv(output)\n",
    "    w2_err = np.dot(w2_delta, NN[2].T)\n",
    "    w1_delta = w2_err * tanh_deriv(l2)\n",
    "    w1_err = np.dot(w1_delta, NN[1].T)\n",
    "    w0_delta = w1_err * tanh_deriv(l1)\n",
    "\n",
    "    NN[0] += np.dot(X.T, w0_delta)\n",
    "    NN[1] += np.dot(l1.T, w1_delta)\n",
    "    NN[2] += np.dot(l2.T, w2_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(NN, X, Y):\n",
    "    backprop(NN, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    mse_before = MSE(Y, forward(NN3, X))\n",
    "    train(NN3, X, Y)\n",
    "    mse_after = MSE(Y, forward(NN3, X))\n",
    "    if i % 10 == 0 or i == 99:\n",
    "        print(\"i: %3i MSE before: %0.5f after: %0.5f\" % (i, mse_before, mse_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splite dataset into sets for testing and training\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X = dataset[list(col)].values\n",
    "Y = dataset[list(cols)].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size =.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (3, 3, 3), max_iter = 500)\n",
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(mlp,X,Y,cv=7)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "training_stats=[]\n",
    "x_fold = np.array_split(X,10)\n",
    "y_fold = np.array_split(Y,10)\n",
    "\n",
    "for k in range(10):\n",
    "    x_train=list(x_fold)\n",
    "    x_test = x_train.pop(k)\n",
    "    x_train=np.concatenate(x_train)\n",
    "    y_train=list(y_fold)\n",
    "    y_test=y_train.pop(k)\n",
    "    y_train=np.concatenate(y_train)\n",
    "    \n",
    "    mse_before = MSE(y_test, forward(NN3, x_test))\n",
    "    train(NN3, x_test, y_test)\n",
    "    mse_after = MSE(y_test, forward(NN3, x_test))\n",
    "    print(\"MSE before:%0.5f after: %0.5f\" % (mse_before, mse_after))\n",
    "    mse_train=MSE(y_train, forward(NN3, x_train))\n",
    "    print(\"MSE one the training set: %0.5f\" % (mse_train))\n",
    "    \n",
    "    training_stats.append([MSE(y_test, forward(NN3, x_test)), MSE(y_train, forward(NN3, x_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLossesKeras\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 3, init = 'uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer ='adam', metrics=['accuracy'])\n",
    "history = model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test),callbacks=[PlotLossesKeras()],verbose=0)\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
